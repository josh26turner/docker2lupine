diff --git a/arch/x86_64/syscall_arch.h b/arch/x86_64/syscall_arch.h
index 92d5c179..531c7cc5 100644
--- a/arch/x86_64/syscall_arch.h
+++ b/arch/x86_64/syscall_arch.h
@@ -1,9 +1,21 @@
 #define __SYSCALL_LL_E(x) (x)
 #define __SYSCALL_LL_O(x) (x)
 
+#define KML
+#ifdef KML
+extern unsigned long __sysinfo;
+#endif
+
+
 static __inline long __syscall0(long n)
 {
 	unsigned long ret;
+#ifdef KML
+    if (__sysinfo) {
+        __asm__ __volatile__ ("call *%1" : "=a"(ret) : "r"(__sysinfo), "a"(n) : "rcx", "r11", "memory");
+        return ret;
+    }
+#endif
 	__asm__ __volatile__ ("syscall" : "=a"(ret) : "a"(n) : "rcx", "r11", "memory");
 	return ret;
 }
@@ -11,6 +23,12 @@ static __inline long __syscall0(long n)
 static __inline long __syscall1(long n, long a1)
 {
 	unsigned long ret;
+#ifdef KML
+    if (__sysinfo) {
+        __asm__ __volatile__ ("call *%1" : "=a"(ret) : "r"(__sysinfo), "a"(n), "D"(a1) : "rcx", "r11", "memory");
+        return ret;
+    }
+#endif   
 	__asm__ __volatile__ ("syscall" : "=a"(ret) : "a"(n), "D"(a1) : "rcx", "r11", "memory");
 	return ret;
 }
@@ -18,6 +36,13 @@ static __inline long __syscall1(long n, long a1)
 static __inline long __syscall2(long n, long a1, long a2)
 {
 	unsigned long ret;
+#ifdef KML
+    if (__sysinfo) {
+        __asm__ __volatile__ ("call *%1" : "=a"(ret) : "r"(__sysinfo), "a"(n), "D"(a1), "S"(a2)
+                              : "rcx", "r11", "memory");
+        return ret;
+    }
+#endif
 	__asm__ __volatile__ ("syscall" : "=a"(ret) : "a"(n), "D"(a1), "S"(a2)
 						  : "rcx", "r11", "memory");
 	return ret;
@@ -26,6 +51,13 @@ static __inline long __syscall2(long n, long a1, long a2)
 static __inline long __syscall3(long n, long a1, long a2, long a3)
 {
 	unsigned long ret;
+#ifdef KML
+    if (__sysinfo) {
+        __asm__ __volatile__ ("call *%1" : "=a"(ret) : "r"(__sysinfo), "a"(n), "D"(a1), "S"(a2),
+                              "d"(a3) : "rcx", "r11", "memory");
+        return ret;
+    }
+#endif
 	__asm__ __volatile__ ("syscall" : "=a"(ret) : "a"(n), "D"(a1), "S"(a2),
 						  "d"(a3) : "rcx", "r11", "memory");
 	return ret;
@@ -34,6 +66,14 @@ static __inline long __syscall3(long n, long a1, long a2, long a3)
 static __inline long __syscall4(long n, long a1, long a2, long a3, long a4)
 {
 	unsigned long ret;
+#ifdef KML
+    if (__sysinfo) {
+        register long r10 __asm__("r10") = a4;
+        __asm__ __volatile__ ("call *%1" : "=a"(ret) : "r"(__sysinfo), "a"(n), "D"(a1), "S"(a2),
+                              "d"(a3), "r"(r10): "rcx", "r11", "memory");
+        return ret;
+    }
+#endif    
 	register long r10 __asm__("r10") = a4;
 	__asm__ __volatile__ ("syscall" : "=a"(ret) : "a"(n), "D"(a1), "S"(a2),
 						  "d"(a3), "r"(r10): "rcx", "r11", "memory");
@@ -43,6 +83,15 @@ static __inline long __syscall4(long n, long a1, long a2, long a3, long a4)
 static __inline long __syscall5(long n, long a1, long a2, long a3, long a4, long a5)
 {
 	unsigned long ret;
+#ifdef KML
+    if (__sysinfo) {
+        register long r10 __asm__("r10") = a4;
+        register long r8 __asm__("r8") = a5;
+        __asm__ __volatile__ ("call *%1" : "=a"(ret) : "r"(__sysinfo), "a"(n), "D"(a1), "S"(a2),
+                              "d"(a3), "r"(r10), "r"(r8) : "rcx", "r11", "memory");
+        return ret;
+    }
+#endif
 	register long r10 __asm__("r10") = a4;
 	register long r8 __asm__("r8") = a5;
 	__asm__ __volatile__ ("syscall" : "=a"(ret) : "a"(n), "D"(a1), "S"(a2),
@@ -53,6 +102,16 @@ static __inline long __syscall5(long n, long a1, long a2, long a3, long a4, long
 static __inline long __syscall6(long n, long a1, long a2, long a3, long a4, long a5, long a6)
 {
 	unsigned long ret;
+#ifdef KML
+    if (__sysinfo) {
+        register long r10 __asm__("r10") = a4;
+        register long r8 __asm__("r8") = a5;
+        register long r9 __asm__("r9") = a6;
+        __asm__ __volatile__ ("call *%1" : "=a"(ret) : "r"(__sysinfo), "a"(n), "D"(a1), "S"(a2),
+                              "d"(a3), "r"(r10), "r"(r8), "r"(r9) : "rcx", "r11", "memory");
+        return ret;
+    }
+#endif
 	register long r10 __asm__("r10") = a4;
 	register long r8 __asm__("r8") = a5;
 	register long r9 __asm__("r9") = a6;
diff --git a/src/thread/pthread_cancel.c b/src/thread/pthread_cancel.c
index 2f9d5e97..ffb160a4 100644
--- a/src/thread/pthread_cancel.c
+++ b/src/thread/pthread_cancel.c
@@ -3,6 +3,8 @@
 #include "pthread_impl.h"
 #include "syscall.h"
 
+#define KML
+
 hidden long __cancel(), __syscall_cp_asm(), __syscall_cp_c();
 
 long __cancel()
@@ -30,7 +32,14 @@ long __syscall_cp_c(syscall_arg_t nr,
 	    && (st==PTHREAD_CANCEL_DISABLE || nr==SYS_close))
 		return __syscall(nr, u, v, w, x, y, z);
 
-	r = __syscall_cp_asm(&self->cancel, nr, u, v, w, x, y, z);
+#ifdef KML
+    if (self->cancel)
+        r = __cancel();
+    else
+        r = __syscall(nr, u, v, w, x, y, z);
+#else
+    r = __syscall_cp_asm(&self->cancel, nr, u, v, w, x, y, z);
+#endif        
 	if (r==-EINTR && nr!=SYS_close && self->cancel &&
 	    self->canceldisable != PTHREAD_CANCEL_DISABLE)
 		r = __cancel();
